{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk import pos_tag\n",
    "\n",
    "vowel_list = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW']\n",
    "consonant_list = ['P', 'B', 'CH', 'D', 'DH', 'F', 'G', 'HH', 'JH', 'K', 'L', 'M', 'N', 'NG', 'R', 'S',\n",
    "                  'SH', 'T', 'TH', 'V', 'W', 'Y', 'Z', 'ZH']\n",
    "\n",
    "syllable_list = vowel_list + consonant_list\n",
    "\n",
    "\n",
    "# vowel_char_combinations = ['A', 'AA', 'AE', 'AEA', 'AEE', 'AEO', 'AEU', 'AI', 'AIA', 'AIE', 'AII', 'AIO', \n",
    "#                            'AIU', 'AO', 'AOA', 'AOI', 'AOU', 'AOUE', 'AU', 'AUA', 'AUE', 'AUI', 'E', 'EA', \n",
    "#                            'EAU', 'EAUI', 'EE', 'EEA', 'EEI', 'EEU', 'EI', 'EIA', 'EIE', 'EO', 'EOA', 'EOI', \n",
    "#                            'EOU', 'EU', 'EUA', 'EUE', 'EUI', 'I', 'IA', 'IAA', 'IAE', 'IAI', 'IAO', 'IAU', \n",
    "#                            'IE', 'IEA', 'IEI', 'IEU', 'II', 'IIO', 'IO', 'IOA', 'IOI', 'IOU', 'IU', 'O', \n",
    "#                            'OA', 'OAI', 'OE', 'OEA', 'OEI', 'OEU', 'OI', 'OIA', 'OIE', 'OO', 'OOE', 'OOI',\n",
    "#                            'OU', 'OUA', 'OUE', 'OUEI', 'OUI', 'U', 'UA', 'UAA', 'UAI', 'UAU', 'UE', 'UEA',\n",
    "#                            'UEE', 'UEI', 'UEOU', 'UEU', 'UEUI', 'UI', 'UIA', 'UIE', 'UO', 'UOI', 'UOIA', \n",
    "#                            'UOU', 'UU']\n",
    "\n",
    "# consonant_char_list = ['B', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V'\n",
    "#                        'W', 'X', 'Y', 'Z']\n",
    "\n",
    "def is_vowel(v):\n",
    "    return '0' in v or '1' in v or '2' in v\n",
    "\n",
    "def has_v_as_ith_vowel_syllable(p, v, i):\n",
    "    vowels_in_p = [j[:-1] for j in p.split(' ') if is_vowel(j)]\n",
    "    if i > len(vowels_in_p):\n",
    "        return False\n",
    "    return v == vowels_in_p[i-1]\n",
    "\n",
    "def has_c_as_ith_vowel_char_combination(w, c, i):\n",
    "    vowels = {'A', 'E', 'I', 'O', 'U'}\n",
    "    res = []\n",
    "    j = 0\n",
    "    while j < len(w):\n",
    "        l = []\n",
    "        if w[j] in vowels:\n",
    "            while w[j] in vowels:\n",
    "                l.append(w[j])\n",
    "                j += 1\n",
    "                if j >= len(w) - 1:\n",
    "                    break\n",
    "            res.append(''.join(l))\n",
    "        else:\n",
    "            j += 1\n",
    "    \n",
    "    if len(res) < i:\n",
    "        return False\n",
    "    return res[i-1] == c\n",
    "\n",
    "def n_syllable_before_ith_vowel_syllable(p, c, i, n):\n",
    "    l = p.split(' ')\n",
    "    count = 0\n",
    "    for j in range(len(l)):\n",
    "        if is_vowel(l[j]):\n",
    "            count += 1\n",
    "            if count == i:\n",
    "                if j <= n-1:\n",
    "                    return False\n",
    "                else:\n",
    "                    ans = l[j-n]\n",
    "                    if is_vowel(ans):\n",
    "                        return ans[:-1] == c\n",
    "                    else:\n",
    "                        return ans == c\n",
    "    return False\n",
    "\n",
    "def n_syllable_after_ith_vowel_syllable(p, c, i, n):\n",
    "    l = p.split(' ')\n",
    "    count = 0\n",
    "    for j in range(len(l)):\n",
    "        if is_vowel(l[j]):\n",
    "            count += 1\n",
    "            if count == i:\n",
    "                if j >= len(l) - n:\n",
    "                    return False\n",
    "                else:\n",
    "                    ans = l[j+n]\n",
    "                    if is_vowel(ans):\n",
    "                        return ans[:-1] == c\n",
    "                    else:\n",
    "                        return ans == c\n",
    "                \n",
    "    return False\n",
    "\n",
    "def has_c_as_consonant_char_before_ith_vowel_char(w, c, i):\n",
    "    vowels = {'A', 'E', 'I', 'O', 'U'}\n",
    "    count = 0\n",
    "    j = 0\n",
    "    while j < len(w):\n",
    "        if w[j] in vowels:\n",
    "            count += 1\n",
    "            \n",
    "            if count == i:\n",
    "                if j == 0:\n",
    "                    return -1\n",
    "                else:\n",
    "                    return w[j-1] == c\n",
    "            \n",
    "            \n",
    "            while w[j] in vowels:\n",
    "                j += 1\n",
    "                if j > len(w) - 1:\n",
    "                    return False\n",
    "        else:\n",
    "            j += 1\n",
    "            \n",
    "    return False\n",
    "\n",
    "def has_c_as_consonant_char_after_ith_vowel_char(w, c, i):\n",
    "    vowels = {'A', 'E', 'I', 'O', 'U'}\n",
    "    count = 0\n",
    "    j = 0\n",
    "    while j < len(w):\n",
    "        if w[j] in vowels:\n",
    "            count += 1\n",
    "            while w[j] in vowels:\n",
    "                j += 1\n",
    "                if j > len(w) - 1:\n",
    "                    return False\n",
    "            \n",
    "                    \n",
    "            if count == i:\n",
    "                if j > len(w) - 1:\n",
    "                    return False\n",
    "                else:\n",
    "                    return w[j] == c\n",
    "        else:\n",
    "            j += 1\n",
    "    return False\n",
    "\n",
    "def find_stress(p):\n",
    "    l = [syllable for syllable in p.split(' ') if is_vowel(syllable)]\n",
    "    for i in range(len(l)):\n",
    "        if '1' in l[i]:\n",
    "            return i + 1\n",
    "\n",
    "def nb_of_vowel_char_combination(w, i):\n",
    "    vowels = {'A', 'E', 'I', 'O', 'U'}\n",
    "    res = []\n",
    "    j = 0\n",
    "    while j < len(w):\n",
    "        l = []\n",
    "        if w[j] in vowels:\n",
    "            while w[j] in vowels:\n",
    "                l.append(w[j])\n",
    "                j += 1\n",
    "                if j >= len(w) - 1:\n",
    "                    break\n",
    "            res.append(''.join(l))\n",
    "        else:\n",
    "            j += 1\n",
    "    return i == len(res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "words, pronounciations = [], []\n",
    "df = pd.DataFrame()\n",
    "file = open('asset/training_data.txt')\n",
    "for line in file:\n",
    "    w, p = line.split(':')\n",
    "    p = p.rstrip('\\n')\n",
    "    words.append(w)\n",
    "    pronounciations.append(p)\n",
    "\n",
    "df['w'] = words\n",
    "df['p'] = pronounciations\n",
    "\n",
    "for v in vowel_list:\n",
    "    for i in range(1, 5):\n",
    "        df[v+str(i)] = df['p'].apply(lambda p: has_v_as_ith_vowel_syllable(p, v, i))\n",
    "        \n",
    "for s in syllable_list:\n",
    "    for i in range(1, 5):\n",
    "        for j in range(1, 3):\n",
    "            name = str(s) + str(j) + 'before' + str(i) + 'vowel syllable'\n",
    "            df[name] = df['p'].apply(lambda p: n_syllable_before_ith_vowel_syllable(p, s, i, j))\n",
    "\n",
    "for s in syllable_list:\n",
    "    for i in range(1, 5):\n",
    "        for j in range(1, 3):\n",
    "            name = str(s) + str(j) + 'after' + str(i) + 'vowel syllable'\n",
    "            df[name] = df['p'].apply(lambda p: n_syllable_after_ith_vowel_syllable(p, s, i, j))\n",
    "\n",
    "# for c in vowel_char_combinations:\n",
    "#     for i in range(1, 5):\n",
    "#         df[c+str(i)] = df['w'].apply(lambda w: has_c_as_ith_vowel_char_combination(w, c, i))        \n",
    "\n",
    "# for c in consonant_char_list:\n",
    "#     for i in range(1, 5):\n",
    "#         df[c+'before_'+str(i)+'_vowel_char'] = df['w'].apply(lambda w: has_c_as_consonant_char_before_ith_vowel_char(w, c, i))\n",
    "\n",
    "# for c in consonant_char_list:\n",
    "#     for i in range(1, 5):\n",
    "#         df[c+'after_'+str(i)+'_vowel_char'] = df['w'].apply(lambda w: has_c_as_consonant_char_after_ith_vowel_char(w, c, i))\n",
    "        \n",
    "\n",
    "df['2 vowel syllables'] = df['p'].apply(lambda p: len([i for i in p.split(' ') if is_vowel(i)]) == 2)\n",
    "df['3 vowel syllables'] = df['p'].apply(lambda p: len([i for i in p.split(' ') if is_vowel(i)]) == 3)\n",
    "df['4 vowel syllables'] = df['p'].apply(lambda p: len([i for i in p.split(' ') if is_vowel(i)]) == 4)\n",
    "\n",
    "df['stress'] = df['p'].apply(find_stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df13 = df[df['stress'] != 4]\n",
    "df4 = df[df['4 vowel syllables'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w                                MUSCLING\n",
       "p                    M AH1 S AH0 L IH0 NG\n",
       "AA1                                 False\n",
       "AA2                                 False\n",
       "AA3                                 False\n",
       "AA4                                 False\n",
       "AE1                                 False\n",
       "AE2                                 False\n",
       "AE3                                 False\n",
       "AE4                                 False\n",
       "AH1                                  True\n",
       "AH2                                  True\n",
       "AH3                                 False\n",
       "AH4                                 False\n",
       "AO1                                 False\n",
       "AO2                                 False\n",
       "AO3                                 False\n",
       "AO4                                 False\n",
       "AW1                                 False\n",
       "AW2                                 False\n",
       "AW3                                 False\n",
       "AW4                                 False\n",
       "AY1                                 False\n",
       "AY2                                 False\n",
       "AY3                                 False\n",
       "AY4                                 False\n",
       "EH1                                 False\n",
       "EH2                                 False\n",
       "EH3                                 False\n",
       "EH4                                 False\n",
       "                             ...         \n",
       "EY3                                 False\n",
       "EY4                                 False\n",
       "IH1                                 False\n",
       "IH2                                 False\n",
       "IH3                                  True\n",
       "IH4                                 False\n",
       "IY1                                 False\n",
       "IY2                                 False\n",
       "IY3                                 False\n",
       "IY4                                 False\n",
       "OW1                                 False\n",
       "OW2                                 False\n",
       "OW3                                 False\n",
       "OW4                                 False\n",
       "OY1                                 False\n",
       "OY2                                 False\n",
       "OY3                                 False\n",
       "OY4                                 False\n",
       "UH1                                 False\n",
       "UH2                                 False\n",
       "UH3                                 False\n",
       "UH4                                 False\n",
       "UW1                                 False\n",
       "UW2                                 False\n",
       "UW3                                 False\n",
       "UW4                                 False\n",
       "2 vowel syllables                   False\n",
       "3 vowel syllables                    True\n",
       "4 vowel syllables                   False\n",
       "stress                                  1\n",
       "Name: 3, Length: 66, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625483080254\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.89      0.93      0.91      7005\n",
      "          2       0.78      0.72      0.75      2396\n",
      "          3       0.74      0.60      0.66       589\n",
      "          4       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.85      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "features = list(df.columns)\n",
    "features.remove('w')\n",
    "features.remove('p')\n",
    "features.remove('stress')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "X_train = train[features]\n",
    "Y_train = train.stress\n",
    "\n",
    "X_test = test[features]\n",
    "Y_test = test.stress\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(Y_test, prediction, average='macro'))\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68837853504\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.89      0.94      0.92      6903\n",
      "          2       0.83      0.72      0.77      2514\n",
      "          3       0.79      0.71      0.75       573\n",
      "          4       0.33      0.30      0.32        10\n",
      "\n",
      "avg / total       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "features = list(df.columns)\n",
    "features.remove('w')\n",
    "features.remove('p')\n",
    "features.remove('stress')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "X_train = train[features]\n",
    "Y_train = train.stress\n",
    "\n",
    "X_test = test[features]\n",
    "Y_test = test.stress\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(Y_test, prediction, average='macro'))\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.474188624245\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.74      0.83      6924\n",
      "          2       0.70      0.55      0.61      2481\n",
      "          3       0.22      0.93      0.36       590\n",
      "          4       0.05      0.80      0.10         5\n",
      "\n",
      "avg / total       0.84      0.71      0.75     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = list(df.columns)\n",
    "features.remove('w')\n",
    "features.remove('p')\n",
    "features.remove('stress')\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "X_train = train[features]\n",
    "Y_train = train.stress\n",
    "\n",
    "X_test = test[features]\n",
    "Y_test = test.stress\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(Y_test, prediction, average='macro'))\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65926002234\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.91      0.91      6949\n",
      "          2       0.83      0.78      0.81      2436\n",
      "          3       0.61      0.83      0.70       605\n",
      "          4       0.13      0.70      0.22        10\n",
      "\n",
      "avg / total       0.88      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = list(df.columns)\n",
    "features.remove('w')\n",
    "features.remove('p')\n",
    "features.remove('stress')\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "X_train = train[features]\n",
    "Y_train = train.stress\n",
    "\n",
    "X_test = test[features]\n",
    "Y_test = test.stress\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(Y_test, prediction, average='macro'))\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674594775475\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.91      0.90      0.91      6939\n",
      "          2       0.82      0.75      0.79      2468\n",
      "          3       0.59      0.85      0.70       583\n",
      "          4       0.21      0.60      0.31        10\n",
      "\n",
      "avg / total       0.87      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = list(df.columns)\n",
    "features.remove('w')\n",
    "features.remove('p')\n",
    "features.remove('stress')\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "X_train = train[features]\n",
    "Y_train = train.stress\n",
    "\n",
    "X_test = test[features]\n",
    "Y_test = test.stress\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(Y_test, prediction, average='macro'))\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763237386295\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.81      0.83       298\n",
      "          2       0.92      0.95      0.94       422\n",
      "          3       0.89      0.91      0.90       464\n",
      "          4       0.57      0.29      0.38        14\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df[df['4 vowel syllables'] == True]\n",
    "df4_1 = df4[df4['stress'] == 1]\n",
    "df4_2 = df4[df4['stress'] == 2]\n",
    "df4_3 = df4[df4['stress'] == 3]\n",
    "df4_4 = df4[df4['stress'] == 4]\n",
    "df4 = df4_1.append(df4_2).append(df4_3).append(df4_4)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "features = list(df.columns)\n",
    "features.remove('w')\n",
    "features.remove('p')\n",
    "features.remove('stress')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "res = []\n",
    "train, test = train_test_split(df4, test_size = 0.2)\n",
    "\n",
    "X_train = train[features]\n",
    "Y_train = train.stress\n",
    "\n",
    "X_test = test[features]\n",
    "Y_test = test.stress\n",
    "\n",
    "clf4 = LogisticRegression()\n",
    "clf4.fit(X_train, Y_train)\n",
    "prediction = clf4.predict(X_test)\n",
    "\n",
    "print(f1_score(Y_test, prediction, average='macro'))\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.73154351623287106, 0.032107516214232107)"
      ]
     },
     "execution_count": 1405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 10\n",
    "df4 = df[df['4 vowel syllables'] == True].copy()\n",
    "df41 = df4[df4['stress'] == 1]\n",
    "df42 = df4[df4['stress'] == 2]\n",
    "df43 = df4[df4['stress'] == 3]\n",
    "df44 = df4[df4['stress'] == 4]\n",
    "df4not4 = df41.append(df42).append(df43)\n",
    "# df4not4['stress'] = 0\n",
    "df4 = df44.append(df4not4)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "features = list(df.columns)\n",
    "features.remove('w')\n",
    "features.remove('p')\n",
    "features.remove('stress')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "res = []\n",
    "for i in range(20):\n",
    "    train, test = train_test_split(df4, test_size = 0.2)\n",
    "\n",
    "    X_train = train[features]\n",
    "    Y_train = train.stress\n",
    "\n",
    "    X_test = test[features]\n",
    "    Y_test = test.stress\n",
    "\n",
    "    clf4 = LogisticRegression()\n",
    "    clf4.fit(X_train, Y_train)\n",
    "    prediction = clf4.predict(X_test)\n",
    "\n",
    "    res.append(f1_score(Y_test, prediction, average='macro'))\n",
    "#     print(classification_report(Y_test, prediction))\n",
    "np.mean(res), np.std(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656415014762\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      1188\n",
      "          4       0.27      0.40      0.32        10\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 10\n",
    "df4 = df[df['4 vowel syllables'] == True].copy()\n",
    "df41 = df4[df4['stress'] == 1]\n",
    "df42 = df4[df4['stress'] == 2]\n",
    "df43 = df4[df4['stress'] == 3]\n",
    "df44 = df4[df4['stress'] == 4]\n",
    "df4not4 = df41.append(df42).append(df43)\n",
    "df4not4['stress'] = 0\n",
    "df4 = df44.append(df4not4)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "features = list(df.columns)\n",
    "features.remove('w')\n",
    "features.remove('p')\n",
    "features.remove('stress')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "train, test = train_test_split(df4, test_size = 0.2)\n",
    "\n",
    "for i in range(7):\n",
    "    train = train.append(train[train['stress'] == 4].copy())\n",
    "\n",
    "\n",
    "X_train = train[features]\n",
    "Y_train = train.stress\n",
    "\n",
    "X_test = test[features]\n",
    "Y_test = test.stress\n",
    "\n",
    "clf4 = LogisticRegression()\n",
    "clf4.fit(X_train, Y_train)\n",
    "prediction = clf4.predict(X_test)\n",
    "\n",
    "print(f1_score(Y_test, prediction, average='macro'))\n",
    "print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>p</th>\n",
       "      <th>AA1</th>\n",
       "      <th>AA2</th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AE1</th>\n",
       "      <th>AE2</th>\n",
       "      <th>AE3</th>\n",
       "      <th>AE4</th>\n",
       "      <th>...</th>\n",
       "      <th>Yafter_2_vowel_char</th>\n",
       "      <th>Yafter_3_vowel_char</th>\n",
       "      <th>Yafter_4_vowel_char</th>\n",
       "      <th>Zafter_1_vowel_char</th>\n",
       "      <th>Zafter_2_vowel_char</th>\n",
       "      <th>Zafter_3_vowel_char</th>\n",
       "      <th>Zafter_4_vowel_char</th>\n",
       "      <th>2 vowel syllables</th>\n",
       "      <th>3 vowel syllables</th>\n",
       "      <th>4 vowel syllables</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>...</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stress</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>...</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "      <td>4744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>...</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           w     p   AA1   AA2   AA3   AA4   AE1   AE2   AE3   AE4  \\\n",
       "       count count count count count count count count count count   \n",
       "stress                                                               \n",
       "0       4744  4744  4744  4744  4744  4744  4744  4744  4744  4744   \n",
       "4       5632  5632  5632  5632  5632  5632  5632  5632  5632  5632   \n",
       "\n",
       "              ...        Yafter_2_vowel_char Yafter_3_vowel_char  \\\n",
       "              ...                      count               count   \n",
       "stress        ...                                                  \n",
       "0             ...                       4744                4744   \n",
       "4             ...                       5632                5632   \n",
       "\n",
       "       Yafter_4_vowel_char Zafter_1_vowel_char Zafter_2_vowel_char  \\\n",
       "                     count               count               count   \n",
       "stress                                                               \n",
       "0                     4744                4744                4744   \n",
       "4                     5632                5632                5632   \n",
       "\n",
       "       Zafter_3_vowel_char Zafter_4_vowel_char 2 vowel syllables  \\\n",
       "                     count               count             count   \n",
       "stress                                                             \n",
       "0                     4744                4744              4744   \n",
       "4                     5632                5632              5632   \n",
       "\n",
       "       3 vowel syllables 4 vowel syllables  \n",
       "                   count             count  \n",
       "stress                                      \n",
       "0                   4744              4744  \n",
       "4                   5632              5632  \n",
       "\n",
       "[2 rows x 1225 columns]"
      ]
     },
     "execution_count": 1395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['stress']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
